{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75e37909-6d07-45e6-a788-d8dfc3b81e03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\HEEMA\n",
      "[nltk_data]     SAMEERA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\HEEMA\n",
      "[nltk_data]     SAMEERA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to C:\\Users\\HEEMA\n",
      "[nltk_data]     SAMEERA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "C:\\Users\\HEEMA SAMEERA\\AppData\\Local\\Temp\\ipykernel_19296\\831032353.py:72: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  custom_dummies = pd.get_dummies(data['custom_categories'].apply(pd.Series).stack()).sum(level=0)\n",
      "C:\\Users\\HEEMA SAMEERA\\AppData\\Local\\Temp\\ipykernel_19296\\831032353.py:72: FutureWarning: Using the level keyword in DataFrame and Series aggregations is deprecated and will be removed in a future version. Use groupby instead. df.sum(level=1) should use df.groupby(level=1).sum().\n",
      "  custom_dummies = pd.get_dummies(data['custom_categories'].apply(pd.Series).stack()).sum(level=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label: CYBER CRIME\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HEEMA SAMEERA\\AppData\\Local\\Temp\\ipykernel_19296\\831032353.py:123: FutureWarning: Using the level keyword in DataFrame and Series aggregations is deprecated and will be removed in a future version. Use groupby instead. df.sum(level=1) should use df.groupby(level=1).sum().\n",
      "  sample_custom_dummies = pd.get_dummies(pd.Series(sample_custom_categories)).sum(level=0)\n"
     ]
    }
   ],
   "source": [
    "# enter your python code here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# Load data\n",
    "data = pd.read_excel(r\"C:\\Users\\HEEMA SAMEERA\\OneDrive\\Desktop\\newsarticleswithcategories.xlsx\")\n",
    "\n",
    "# Preprocessing function\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('vader_lexicon')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.lower()  # Lowercase\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation and special characters\n",
    "    tokens = text.split()  # Tokenization\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens if token not in stop_words]  # Remove stop words and lemmatize\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "data['text'] = data['text'].apply(preprocess)\n",
    "\n",
    "# Feature extraction using TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_tfidf = vectorizer.fit_transform(data['text'])\n",
    "\n",
    "# Sentiment Analysis\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "def sentiment_analysis(text):\n",
    "    sentiment_scores = analyzer.polarity_scores(text)\n",
    "    return [sentiment_scores['neg'], sentiment_scores['neu'], sentiment_scores['pos'], sentiment_scores['compound']]\n",
    "\n",
    "data['sentiment'] = data['text'].apply(sentiment_analysis)\n",
    "\n",
    "# Define custom patterns for each category\n",
    "patterns = {\n",
    "    'ANTI_GOVERNMENT_ACT': r'anti-government|protest|demonstration|riot|rebellion|sedition',\n",
    "    'ARSON': r'arson|fire|burn',\n",
    "    'COMMUNAL_RELIGIOUS': r'communal|religious|sectarian|sectarianism',\n",
    "    'CYBER_CRIME': r'cybercrime|cyber crime|online crime|hacking|phishing',\n",
    "    'JAILS': r'jail|prison|detention center',\n",
    "    'MAFIA': r'mafia|gang|organized crime|mob',\n",
    "    'MURDER': r'murder|kill|homicide|killed',\n",
    "    'NDPS': r'NDPS|narcotic|drug|psychoactive substance',\n",
    "    'RAPE': r'rape|sexual assault|sexual violence',\n",
    "    'TERRORISM': r'terrorism|terrorist|bombing|attack',\n",
    "    'THEFT_ROBBERY': r'theft|robbery|burglary|steal'\n",
    "}\n",
    "\n",
    "# Function to identify categories based on custom patterns\n",
    "def identify_category(text):\n",
    "    categories = []\n",
    "    for category, pattern in patterns.items():\n",
    "        if re.search(pattern, text, re.IGNORECASE):\n",
    "            categories.append(category)\n",
    "    return categories\n",
    "\n",
    "# Apply custom pattern matching to identify categories\n",
    "data['custom_categories'] = data['text'].apply(identify_category)\n",
    "\n",
    "# Convert custom categories to dummy variables\n",
    "custom_dummies = pd.get_dummies(data['custom_categories'].apply(pd.Series).stack()).sum(level=0)\n",
    "\n",
    "# Reshape sentiment features to be 2-dimensional\n",
    "sentiment_features = np.array(data['sentiment'].tolist())\n",
    "\n",
    "# Ensure custom_dummies has the same number of samples as X_tfidf and align their indices\n",
    "custom_dummies = custom_dummies.reindex(index=range(X_tfidf.shape[0]), columns=range(custom_dummies.shape[1]), fill_value=0)\n",
    "\n",
    "# Combine TF-IDF features with sentiment features and custom pattern dummy variables\n",
    "X = np.hstack((X_tfidf.toarray(), sentiment_features, custom_dummies.to_numpy()))\n",
    "y = data['label']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Gradient Boosting classifier\n",
    "gradient_boosting = GradientBoostingClassifier(random_state=42)\n",
    "gradient_boosting.fit(X_train, y_train)\n",
    "\n",
    "# Sample text to test\n",
    "sample_text = \"\"\"\n",
    "A group of hackers launched a cyber attack on the government's website yesterday. The attack caused significant disruption to online services, leading to concerns about the security of sensitive information.\n",
    "\"\"\"\n",
    "\n",
    "# Preprocess the sample text\n",
    "sample_text_processed = preprocess(sample_text)\n",
    "\n",
    "# Vectorize the preprocessed sample text using TF-IDF\n",
    "sample_text_vectorized = vectorizer.transform([sample_text_processed])\n",
    "\n",
    "# Perform sentiment analysis on the sample text\n",
    "sample_sentiment = sentiment_analysis(sample_text_processed)\n",
    "sample_sentiment_features = np.array([sample_sentiment])\n",
    "\n",
    "# # Apply custom pattern matching to identify categories for the sample text\n",
    "# sample_custom_categories = identify_category(sample_text_processed)\n",
    "\n",
    "# # Ensure sample_custom_dummies has the same number of rows as sample_text_vectorized and sample_sentiment_features\n",
    "# sample_custom_dummies = sample_custom_dummies.reindex(index=range(sample_text_vectorized.shape[0]), columns=custom_dummies.columns, fill_value=0)\n",
    "\n",
    "# # Combine TF-IDF features with sentiment features and custom pattern dummy variables for the sample text\n",
    "# sample_features = np.hstack((sample_text_vectorized.toarray(), sample_sentiment_features, sample_custom_dummies.to_numpy()))\n",
    "\n",
    "# # Predict the label of the sample text\n",
    "# predicted_label = gradient_boosting.predict(sample_features)[0]\n",
    "# print(\"Predicted Label:\", predicted_label)\n",
    "\n",
    "# Identify categories for the sample text\n",
    "sample_custom_categories = identify_category(sample_text_processed)\n",
    "\n",
    "# Convert sample_custom_categories to dummy variables\n",
    "sample_custom_dummies = pd.get_dummies(pd.Series(sample_custom_categories)).sum(level=0)\n",
    "\n",
    "# Ensure sample_custom_dummies has the same number of columns as custom_dummies and fill with zeros if necessary\n",
    "sample_custom_dummies = sample_custom_dummies.reindex(columns=custom_dummies.columns, fill_value=0)\n",
    "\n",
    "# Combine TF-IDF features with sentiment features and custom pattern dummy variables for the sample text\n",
    "sample_features = np.hstack((sample_text_vectorized.toarray(), sample_sentiment_features, sample_custom_dummies.to_numpy()))\n",
    "\n",
    "# Predict the label of the sample text\n",
    "predicted_label = gradient_boosting.predict(sample_features)[0]\n",
    "print(\"Predicted Label:\", predicted_label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8aea266-8654-48e9-99d4-758533cc57da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "ANTI GOVERNMENT ACT       0.67      0.86      0.75         7\n",
      "              ARSON       1.00      0.86      0.92         7\n",
      " COMMUNAL/RELIGIOUS       0.40      0.29      0.33         7\n",
      "        CYBER CRIME       0.50      0.67      0.57         3\n",
      "              JAILS       1.00      0.33      0.50         6\n",
      "              MAFIA       0.23      0.75      0.35         4\n",
      "             MURDER       1.00      0.75      0.86         4\n",
      "               NDPS       0.75      0.60      0.67         5\n",
      "               RAPE       1.00      1.00      1.00         2\n",
      "          TERRORISM       1.00      0.62      0.77         8\n",
      "      THEFT/ROBBERY       1.00      1.00      1.00         2\n",
      "\n",
      "           accuracy                           0.65        55\n",
      "          macro avg       0.78      0.70      0.70        55\n",
      "       weighted avg       0.78      0.65      0.67        55\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Predict the labels for the test set\n",
    "y_pred = gradient_boosting.predict(X_test)\n",
    "\n",
    "# Generate classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "691bd3eb-cb36-4d06-bbe3-3b3f68c25be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label: RAPE\n"
     ]
    }
   ],
   "source": [
    "# Sample text to test\n",
    "sample_text = \"18 year old gang raped in hyd \"\n",
    "\n",
    "# Preprocess the sample text\n",
    "sample_text_processed = preprocess(sample_text)\n",
    "\n",
    "# Vectorize the preprocessed sample text using TF-IDF\n",
    "sample_text_vectorized = vectorizer.transform([sample_text_processed])\n",
    "\n",
    "# Perform sentiment analysis on the sample text\n",
    "sample_sentiment = sentiment_analysis(sample_text_processed)\n",
    "sample_sentiment_features = np.array([sample_sentiment])\n",
    "\n",
    "# Apply custom pattern matching to identify categories for the sample text\n",
    "sample_custom_categories = identify_category(sample_text_processed)\n",
    "\n",
    "# Ensure sample_custom_dummies has the same number of rows as sample_text_vectorized and sample_sentiment_features\n",
    "sample_custom_dummies = sample_custom_dummies.reindex(index=range(sample_text_vectorized.shape[0]), columns=custom_dummies.columns, fill_value=0)\n",
    "\n",
    "# Combine TF-IDF features with sentiment features and custom pattern dummy variables for the sample text\n",
    "sample_features = np.hstack((sample_text_vectorized.toarray(), sample_sentiment_features, sample_custom_dummies.to_numpy()))\n",
    "\n",
    "# Predict the label of the sample text\n",
    "predicted_label = gradient_boosting.predict(sample_features)[0]\n",
    "print(\"Predicted Label:\", predicted_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42d39268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label: MAFIA\n"
     ]
    }
   ],
   "source": [
    "# Sample text to test\n",
    "sample_text = \"cyber attack everywhere \"\n",
    "\n",
    "# Preprocess the sample text\n",
    "sample_text_processed = preprocess(sample_text)\n",
    "\n",
    "# Vectorize the preprocessed sample text using TF-IDF\n",
    "sample_text_vectorized = vectorizer.transform([sample_text_processed])\n",
    "\n",
    "# Perform sentiment analysis on the sample text\n",
    "sample_sentiment = sentiment_analysis(sample_text_processed)\n",
    "sample_sentiment_features = np.array([sample_sentiment])\n",
    "\n",
    "# Apply custom pattern matching to identify categories for the sample text\n",
    "sample_custom_categories = identify_category(sample_text_processed)\n",
    "\n",
    "# Ensure sample_custom_dummies has the same number of rows as sample_text_vectorized and sample_sentiment_features\n",
    "sample_custom_dummies = sample_custom_dummies.reindex(index=range(sample_text_vectorized.shape[0]), columns=custom_dummies.columns, fill_value=0)\n",
    "\n",
    "# Combine TF-IDF features with sentiment features and custom pattern dummy variables for the sample text\n",
    "sample_features = np.hstack((sample_text_vectorized.toarray(), sample_sentiment_features, sample_custom_dummies.to_numpy()))\n",
    "\n",
    "# Predict the label of the sample text\n",
    "predicted_label = gradient_boosting.predict(sample_features)[0]\n",
    "print(\"Predicted Label:\", predicted_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f78f846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label: MAFIA\n"
     ]
    }
   ],
   "source": [
    "# Sample text to test\n",
    "sample_text = \"knife kills uncle\"\n",
    "\n",
    "# Preprocess the sample text\n",
    "sample_text_processed = preprocess(sample_text)\n",
    "\n",
    "# Vectorize the preprocessed sample text using TF-IDF\n",
    "sample_text_vectorized = vectorizer.transform([sample_text_processed])\n",
    "\n",
    "# Perform sentiment analysis on the sample text\n",
    "sample_sentiment = sentiment_analysis(sample_text_processed)\n",
    "sample_sentiment_features = np.array([sample_sentiment])\n",
    "\n",
    "# Apply custom pattern matching to identify categories for the sample text\n",
    "sample_custom_categories = identify_category(sample_text_processed)\n",
    "\n",
    "# Ensure sample_custom_dummies has the same number of rows as sample_text_vectorized and sample_sentiment_features\n",
    "sample_custom_dummies = sample_custom_dummies.reindex(index=range(sample_text_vectorized.shape[0]), columns=custom_dummies.columns, fill_value=0)\n",
    "\n",
    "# Combine TF-IDF features with sentiment features and custom pattern dummy variables for the sample text\n",
    "sample_features = np.hstack((sample_text_vectorized.toarray(), sample_sentiment_features, sample_custom_dummies.to_numpy()))\n",
    "\n",
    "# Predict the label of the sample text\n",
    "predicted_label = gradient_boosting.predict(sample_features)[0]\n",
    "print(\"Predicted Label:\", predicted_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25cdd78e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label: NDPS\n"
     ]
    }
   ],
   "source": [
    "# Sample text to test\n",
    "sample_text = \"drugs found in the hitech city tunnel along with 12 other weapons \"\n",
    "# Preprocess the sample text\n",
    "sample_text_processed = preprocess(sample_text)\n",
    "\n",
    "# Vectorize the preprocessed sample text using TF-IDF\n",
    "sample_text_vectorized = vectorizer.transform([sample_text_processed])\n",
    "\n",
    "# Perform sentiment analysis on the sample text\n",
    "sample_sentiment = sentiment_analysis(sample_text_processed)\n",
    "sample_sentiment_features = np.array([sample_sentiment])\n",
    "\n",
    "# Apply custom pattern matching to identify categories for the sample text\n",
    "sample_custom_categories = identify_category(sample_text_processed)\n",
    "\n",
    "# Ensure sample_custom_dummies has the same number of rows as sample_text_vectorized and sample_sentiment_features\n",
    "sample_custom_dummies = sample_custom_dummies.reindex(index=range(sample_text_vectorized.shape[0]), columns=custom_dummies.columns, fill_value=0)\n",
    "\n",
    "# Combine TF-IDF features with sentiment features and custom pattern dummy variables for the sample text\n",
    "sample_features = np.hstack((sample_text_vectorized.toarray(), sample_sentiment_features, sample_custom_dummies.to_numpy()))\n",
    "\n",
    "# Predict the label of the sample text\n",
    "predicted_label = gradient_boosting.predict(sample_features)[0]\n",
    "print(\"Predicted Label:\", predicted_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92d09a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label: TERRORISM\n"
     ]
    }
   ],
   "source": [
    "# Sample text to test\n",
    "sample_text = \"terrorism breaks out in mumbai \"\n",
    "# Preprocess the sample text\n",
    "sample_text_processed = preprocess(sample_text)\n",
    "\n",
    "# Vectorize the preprocessed sample text using TF-IDF\n",
    "sample_text_vectorized = vectorizer.transform([sample_text_processed])\n",
    "\n",
    "# Perform sentiment analysis on the sample text\n",
    "sample_sentiment = sentiment_analysis(sample_text_processed)\n",
    "sample_sentiment_features = np.array([sample_sentiment])\n",
    "\n",
    "# Apply custom pattern matching to identify categories for the sample text\n",
    "sample_custom_categories = identify_category(sample_text_processed)\n",
    "\n",
    "# Ensure sample_custom_dummies has the same number of rows as sample_text_vectorized and sample_sentiment_features\n",
    "sample_custom_dummies = sample_custom_dummies.reindex(index=range(sample_text_vectorized.shape[0]), columns=custom_dummies.columns, fill_value=0)\n",
    "\n",
    "# Combine TF-IDF features with sentiment features and custom pattern dummy variables for the sample text\n",
    "sample_features = np.hstack((sample_text_vectorized.toarray(), sample_sentiment_features, sample_custom_dummies.to_numpy()))\n",
    "\n",
    "# Predict the label of the sample text\n",
    "predicted_label = gradient_boosting.predict(sample_features)[0]\n",
    "print(\"Predicted Label:\", predicted_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e761604e-35e3-477f-b6eb-562b04fccd53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label: TERRORISM\n"
     ]
    }
   ],
   "source": [
    "# Sample text to test\n",
    "sample_text = ''' An Israeli strike on a school sheltering displaced Palestinians in central Gaza killed at least 33 people on Thursday. Following the attack, the Israel Defense Forces said Hamas terrorists were operating from within the school. Meanwhile, Qatar Foreign Ministry has said that Hamas has not yet handed mediators its response to the latest ceasefire proposal and is still studying it. Amid the ongoing war, Israeli Prime Minister Benjamin Netanyahu is set to address a joint meeting of Congress on July 24, The Associated Press reported, citing two people familiar with the matter. The war began after Hamas attacked Israel on October 7, killing around 1,200 people and capturing more than 250 hostages.At least 33 people were killed after Israel hit a Gaza school on Thursday. Video footage showed Palestinians hauling away bodies and scores of injured in a hospital after the attack, which took place at a sensitive moment in mediated talks on a ceasefire that would involve releasing hostages held by Hamas and some of the Palestinians held in Israeli jails. Following the strike, the Israeli military said the central Gaza compound was being used by terrorists. Addressing a press conference, an IDF spokesperson said those targeted were members of Hamas's elite Nukhba force and of the Palestinian Islamic Jihad terror group who \"directed terror attacks from the area of the school while exploiting it as a civilian location and as a shelter. The terrorists inside this school were planning more attacks against Israelis, some of them imminent.\" Meanwhile, the US State Department has said the country has been in contact with Israel about the strike at Gaza school. State Department spokesperson Matthew Miller also said that Washington expects Israel to be fully transparent in making information about the strike public. On Thursday, Qatari foreign ministry spokesperson Majed Al-Ansari said Hamas has not yet handed mediators its response to the latest ceasefire proposal and is still studying it, adding that Qatari, Egyptian and US mediators were still making efforts. Talks began on Wednesday when Central Intelligence Agency (CIA) director William Burns met senior officials from Qatar and Egypt in Doha to discuss a proposal that US President Joe Biden publicly endorsed last week. Russia and China, which hold veto powers in the United Nations Security Council, raised concerns on Thursday with a US draft resolution that would back a proposal - outlined by President Joe Biden - for a ceasefire between Israel and Hamas. The council's only Arab member, Algeria, also signalled it was not ready to back the text, diplomats said. A resolution needs at least nine votes in favour and no vetoes by the US, France, Britain, China or Russia to pass. Benjamin Netanyahu is set to address a joint meeting of Congress on July 24, The Associated Press quoted two people familiar with the matter as saying. Last week, Congressional leaders formally invited Netanyahu to come speak. However, the date of the speech had been in flux. According to news agency Reuters, Netanyahu, over his upcoming speech, said he was \"very moved to have the privilege of representing Israel before both Houses of Congress and to present the truth about our just war.\" On Thursday, Israeli forces killed three Palestinians and injured at least 13 others in a raid on the occupied West Bank city of Jenin, Reuters quoted the Palestinian Health Ministry and medics as saying. The Palestine Red Crescent Society said it was treating at least six people who were shot, four who sustained shrapnel wounds and one person who was run over by a military jeep. It said its teams were fired at while recovering some of the dead.'''\n",
    "# Preprocess the sample text\n",
    "sample_text_processed = preprocess(sample_text)\n",
    "\n",
    "# Vectorize the preprocessed sample text using TF-IDF\n",
    "sample_text_vectorized = vectorizer.transform([sample_text_processed])\n",
    "\n",
    "# Perform sentiment analysis on the sample text\n",
    "sample_sentiment = sentiment_analysis(sample_text_processed)\n",
    "sample_sentiment_features = np.array([sample_sentiment])\n",
    "\n",
    "# Apply custom pattern matching to identify categories for the sample text\n",
    "sample_custom_categories = identify_category(sample_text_processed)\n",
    "\n",
    "# Ensure sample_custom_dummies has the same number of rows as sample_text_vectorized and sample_sentiment_features\n",
    "sample_custom_dummies = sample_custom_dummies.reindex(index=range(sample_text_vectorized.shape[0]), columns=custom_dummies.columns, fill_value=0)\n",
    "\n",
    "# Combine TF-IDF features with sentiment features and custom pattern dummy variables for the sample text\n",
    "sample_features = np.hstack((sample_text_vectorized.toarray(), sample_sentiment_features, sample_custom_dummies.to_numpy()))\n",
    "\n",
    "# Predict the label of the sample text\n",
    "predicted_label = gradient_boosting.predict(sample_features)[0]\n",
    "print(\"Predicted Label:\", predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64d052bd-dbe8-4093-a1a8-571e414a6b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6545454545454545\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Predict labels for the test set\n",
    "y_pred = gradient_boosting.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
