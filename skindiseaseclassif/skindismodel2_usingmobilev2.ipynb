{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nJAVmqynQXH",
        "outputId": "ed488a85-8e68-4db0-e8b1-bd25e1b62122"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 15590 files belonging to 23 classes.\n",
            "Found 4029 files belonging to 23 classes.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "# Parameters\n",
        "img_height, img_width = 224, 224\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "train_dir = '/content/drive/MyDrive/data/train'\n",
        "validation_dir = '/content/drive/MyDrive/data/test'\n",
        "\n",
        "# Data preparation using image_dataset_from_directory\n",
        "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    image_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    label_mode='categorical'\n",
        ")\n",
        "\n",
        "validation_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "    validation_dir,\n",
        "    image_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    label_mode='categorical'\n",
        ")\n",
        "\n",
        "# Determine the correct number of classes\n",
        "num_classes = len(train_dataset.class_names)  # Get the number of classes from the dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pre-trained MobileNetV2 model + higher level layers\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n",
        "\n",
        "# Add custom layers on top\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "predictions = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "# Create the final model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Freeze the base model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HBsNo14nvQ1",
        "outputId": "e9daef6b-d0f8-47bd-926a-affc44bce555"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Callbacks\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.00001)\n"
      ],
      "metadata": {
        "id": "oEquSubinc46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model with callbacks\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_dataset,\n",
        "    callbacks=[early_stopping, reduce_lr]\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHgnAipLnhBc",
        "outputId": "59ffcd9d-d742-41d5-9629-69fa233069b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2468s\u001b[0m 5s/step - accuracy: 0.1552 - loss: 2.9312 - val_accuracy: 0.1770 - val_loss: 2.7113 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1104s\u001b[0m 2s/step - accuracy: 0.2125 - loss: 2.6386 - val_accuracy: 0.2122 - val_loss: 2.6492 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1092s\u001b[0m 2s/step - accuracy: 0.2381 - loss: 2.5563 - val_accuracy: 0.2303 - val_loss: 2.5886 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1117s\u001b[0m 2s/step - accuracy: 0.2555 - loss: 2.4778 - val_accuracy: 0.2254 - val_loss: 2.6091 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1155s\u001b[0m 2s/step - accuracy: 0.2672 - loss: 2.4167 - val_accuracy: 0.2316 - val_loss: 2.5940 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1087s\u001b[0m 2s/step - accuracy: 0.2961 - loss: 2.3436 - val_accuracy: 0.2417 - val_loss: 2.5880 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1112s\u001b[0m 2s/step - accuracy: 0.3107 - loss: 2.2772 - val_accuracy: 0.2489 - val_loss: 2.5789 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1112s\u001b[0m 2s/step - accuracy: 0.3290 - loss: 2.2201 - val_accuracy: 0.2554 - val_loss: 2.5927 - learning_rate: 0.0010\n",
            "Epoch 9/10\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1114s\u001b[0m 2s/step - accuracy: 0.3587 - loss: 2.1398 - val_accuracy: 0.2529 - val_loss: 2.6372 - learning_rate: 0.0010\n",
            "Epoch 10/10\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1090s\u001b[0m 2s/step - accuracy: 0.3694 - loss: 2.0917 - val_accuracy: 0.2517 - val_loss: 2.6610 - learning_rate: 0.0010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = '/content/drive/MyDrive/demoimg_skinvmax/mobilenetv2_image_classifier.keras'\n",
        "# Save the model\n",
        "model.save(model_path)\n",
        "print(\"Model training complete and saved in Keras format.\")\n",
        "\n",
        "# Load the trained model\n",
        "model = tf.keras.models.load_model('/content/drive/MyDrive/demoimg_skinvmax/mobilenetv2_image_classifier.keras')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUKh3QjMnh4y",
        "outputId": "a93dd64d-51bc-4646-d3f7-330babd3270c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model training complete and saved in Keras format.\n"
          ]
        }
      ]
    }
  ]
}